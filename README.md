# Person Matching Solution - AWS Distributed Architecture

## ğŸ“‹ VisÃ£o Geral

SoluÃ§Ã£o escalÃ¡vel para comparaÃ§Ã£o e matching de milhÃµes de registros de pessoas utilizando algoritmos de similaridade (Levenshtein, Jaro-Winkler, Soundex) e computaÃ§Ã£o distribuÃ­da na AWS.

### CaracterÃ­sticas Principais

- âœ… **Processamento DistribuÃ­do**: Apache Spark em EMR para processar terabytes de dados
- âœ… **DetecÃ§Ã£o de Deltas**: Processa apenas alteraÃ§Ãµes incrementais para eficiÃªncia
- âœ… **IndexaÃ§Ã£o RÃ¡pida**: OpenSearch para busca instantÃ¢nea por `nr_documento`
- âœ… **Cache Inteligente**: Redis/ElastiCache para deduplicaÃ§Ã£o e cache
- âœ… **Infraestrutura como CÃ³digo**: Terraform para toda infraestrutura AWS
- âœ… **Auto-scaling**: Escalabilidade automÃ¡tica baseada em carga
- âœ… **Multi-algoritmos**: CombinaÃ§Ã£o de Levenshtein, Jaro-Winkler e Soundex

## ğŸ—ï¸ Arquitetura

```mermaid
graph TB
    subgraph AWS["AWS Cloud"]
        S31[(S3 Dataset 1)]
        S32[(S3 Dataset 2)]
        S3R[(S3 Results)]
        
        EB[EventBridge + Lambda<br/>Delta Detector]
        
        EMR[EMR Cluster<br/>Apache Spark]
        
        OS[(OpenSearch<br/>Index)]
        DDB[(DynamoDB<br/>State)]
        Redis[(Redis<br/>Cache)]
        
        subgraph Glue["AWS Glue Data Catalog"]
            GT1[Dataset 1 Table]
            GT2[Dataset 2 Table]
            GTR[Results Table]
        end
        
        S31 -->|S3 Event| EB
        S32 -->|S3 Event| EB
        EB -->|Trigger| EMR
        
        EMR -->|Read Metadata| Glue
        EMR -->|Read Data| S31
        EMR -->|Read Data| S32
        
        EMR -->|Write Results| S3R
        EMR -->|Index Matches| OS
        EMR -->|Update State| DDB
        
        OS <-->|Cache| Redis
        DDB <-->|Cache| Redis
        
        Glue -.->|Schema| EMR
    end
    
    User[User/API] -->|Query| OS
    OS -->|Results| User
    
    style AWS fill:#fff,stroke:#FF9900,stroke-width:3px
    style EMR fill:#FF9900,stroke:#232F3E,color:#fff
    style OS fill:#4A90E2,stroke:#232F3E,color:#fff
    style Redis fill:#DC382D,stroke:#232F3E,color:#fff
    style Glue fill:#8C4FFF,stroke:#232F3E,color:#fff
```

## ğŸ“Š Entidade Pessoa

```python
{
    "nome_completo": str,      # Nome completo da pessoa
    "data_nascimento": str,    # Formato: YYYY-MM-DD
    "nr_documento": str,       # CPF, RG, etc.
    "status": str              # Ativo, Inativo, etc.
}
```

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Docker & Docker Compose
- Terraform >= 1.5.0
- AWS CLI configurado
- Python 3.11+

### Desenvolvimento Local

```bash
# 1. Clone o repositÃ³rio
git clone <repo-url>
cd poc_lucene

# 2. Inicie os containers
docker-compose up -d

# 3. Acesse as interfaces
# Spark Master UI: http://localhost:8080
# OpenSearch: http://localhost:9200
# OpenSearch Dashboards: http://localhost:5601
# Jupyter: http://localhost:8888
# LocalStack: http://localhost:4566
```

### Deploy na AWS

```bash
# 1. Inicialize o Terraform
cd terraform
terraform init

# 2. Configure as variÃ¡veis
cp terraform.tfvars.example terraform.tfvars
# Edite terraform.tfvars com seus valores

# 3. Planeje e aplique
terraform plan
terraform apply

# 4. Upload dos scripts para S3
aws s3 cp ../app/person_matcher.py s3://$(terraform output -raw s3_bucket_scripts)/
aws s3 cp ../app/opensearch_indexer.py s3://$(terraform output -raw s3_bucket_scripts)/

# 5. Execute os crawlers do Glue
aws glue start-crawler --name person-matching-dataset1-crawler
aws glue start-crawler --name person-matching-dataset2-crawler
```

## ğŸ”§ Componentes

### 1. Person Matcher (PySpark)

Algoritmo principal de matching distribuÃ­do:

- **Blocking Strategy**: Reduz espaÃ§o de comparaÃ§Ã£o usando primeira letra + ano nascimento
- **Levenshtein Distance**: Similaridade de strings (0-1)
- **Jaro-Winkler**: Otimizado para nomes prÃ³prios
- **Soundex**: Matching fonÃ©tico
- **Score Composto**: MÃ©dia ponderada dos algoritmos

**Pesos do Score:**
```
similarity_score = 
    name_levenshtein * 0.25 +
    name_jaro_winkler * 0.25 +
    name_soundex * 0.15 +
    date_similarity * 0.25 +
    document_exact_match * 0.10
```

### 2. Delta Detector (Lambda)

Detecta mudanÃ§as nos datasets e processa apenas deltas:

- Monitora S3 via eventos
- Calcula hash de metadata
- Compara com estado anterior (DynamoDB)
- Dispara EMR step apenas se houver mudanÃ§as
- Executa 4x ao dia via CloudWatch Events

### 3. OpenSearch Indexer

Indexa resultados para busca rÃ¡pida:

- Index otimizado para busca por `nr_documento`
- Analyzers customizados para nomes
- Busca bidirecional (nr_documento_1 ou nr_documento_2)
- OrdenaÃ§Ã£o por `similarity_score`

### 4. Infraestrutura AWS

**EMR Cluster:**
- Master: m5.xlarge
- Core: m5.2xlarge (3-10 nodes auto-scaling)
- Spark 3.x com otimizaÃ§Ãµes
- IntegraÃ§Ã£o com Glue Catalog

**OpenSearch:**
- r6g.xlarge.search (3 nodes)
- 100GB EBS por node
- Multi-AZ para alta disponibilidade
- VPC isolada

**ElastiCache (Redis):**
- cache.r6g.xlarge (2 nodes)
- Cluster mode habilitado
- Usado para cache e deduplicaÃ§Ã£o

## ğŸ“ˆ Performance e Escalabilidade

### OtimizaÃ§Ãµes Implementadas

1. **Blocking Strategy**: Reduz comparaÃ§Ãµes de O(nÂ²) para O(n log n)
2. **Particionamento**: Dados particionados por blocking_key
3. **Broadcast Joins**: Para datasets menores
4. **Adaptive Query Execution**: Spark AQE habilitado
5. **Dynamic Allocation**: Executores alocados sob demanda
6. **Caching**: Redis para resultados intermediÃ¡rios

### Capacidade Estimada

| Dataset Size | Processing Time | EMR Nodes | Custo/Run (est.) |
|--------------|----------------|-----------|------------------|
| 10M records  | ~30 min        | 3 core    | $15              |
| 100M records | ~4 hours       | 6 core    | $80              |
| 1B records   | ~24 hours      | 10 core   | $400             |

## ğŸ” Como Buscar Resultados

### Via OpenSearch REST API

```bash
# Buscar matches por nr_documento
curl -X POST "https://<opensearch-endpoint>/_search" \
  -H 'Content-Type: application/json' \
  -d '{
    "query": {
      "bool": {
        "should": [
          {"term": {"nr_documento_1": "12345678900"}},
          {"term": {"nr_documento_2": "12345678900"}}
        ]
      }
    },
    "sort": [{"similarity_score": "desc"}],
    "size": 10
  }'
```

### Via Python

```python
from opensearchpy import OpenSearch

client = OpenSearch(
    hosts=[{'host': 'your-endpoint.us-east-1.es.amazonaws.com', 'port': 443}],
    use_ssl=True
)

# Buscar matches
response = client.search(
    index='person-matches',
    body={
        'query': {
            'bool': {
                'should': [
                    {'term': {'nr_documento_1': '12345678900'}},
                    {'term': {'nr_documento_2': '12345678900'}}
                ]
            }
        },
        'sort': [{'similarity_score': {'order': 'desc'}}],
        'size': 10
    }
)

for hit in response['hits']['hits']:
    print(hit['_source'])
```

## ğŸ”„ Pipeline de ExecuÃ§Ã£o

```
1. Upload de dados â†’ S3 Buckets
2. S3 Event â†’ Lambda Delta Detector
3. Lambda verifica mudanÃ§as (DynamoDB)
4. Se houver mudanÃ§as â†’ EMR Step
5. Spark lÃª via Glue Catalog
6. Processamento distribuÃ­do com blocking
7. Resultados â†’ S3 (Parquet)
8. IndexaÃ§Ã£o â†’ OpenSearch
9. Busca disponÃ­vel via API
```

## ğŸ›¡ï¸ SeguranÃ§a

- âœ… Buckets S3 com criptografia AES-256
- âœ… OpenSearch em VPC privada
- âœ… Redis com criptografia em trÃ¢nsito e repouso
- âœ… IAM roles com princÃ­pio de menor privilÃ©gio
- âœ… VPC endpoints para S3 e DynamoDB
- âœ… Security groups restritivos
- âœ… Logs centralizados no CloudWatch

## ğŸ’° Estimativa de Custos (Mensal)

| Componente | ConfiguraÃ§Ã£o | Custo/MÃªs |
|------------|--------------|-----------|
| EMR (on-demand, 8h/dia) | 1 master + 3 core | $800 |
| OpenSearch | 3x r6g.xlarge | $900 |
| ElastiCache | 2x cache.r6g.xlarge | $450 |
| S3 Storage | 5TB | $115 |
| Data Transfer | 1TB | $90 |
| Lambda | 1M invocations | $0.20 |
| DynamoDB | On-demand | $25 |
| **TOTAL** | | **~$2,380/mÃªs** |

*Nota: Use EMR Spot Instances para reduzir custos em ~70%*

## ğŸ§ª Testes

### Teste Local com Docker

```bash
# Gerar dados de teste
python scripts/generate_test_data.py --records 10000

# Executar matching local
docker-compose exec app python /app/person_matcher.py \
  person_data dataset1 dataset2 /data/output 0.7
```

### Teste de Performance

```bash
# Executar benchmark
python scripts/benchmark.py \
  --size 1000000 \
  --workers 4 \
  --threshold 0.7
```

## ğŸ“š Estrutura do Projeto

```
poc_lucene/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ person_matcher.py          # Spark job principal
â”‚   â”œâ”€â”€ opensearch_indexer.py      # Indexador OpenSearch
â”‚   â””â”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ lambdas/
â”‚   â””â”€â”€ delta_detector.py           # Lambda de detecÃ§Ã£o de deltas
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf                     # ConfiguraÃ§Ã£o principal
â”‚   â”œâ”€â”€ variables.tf                # VariÃ¡veis
â”‚   â”œâ”€â”€ vpc.tf                      # VPC e networking
â”‚   â”œâ”€â”€ emr.tf                      # EMR cluster
â”‚   â”œâ”€â”€ opensearch.tf               # OpenSearch domain
â”‚   â”œâ”€â”€ elasticache.tf              # Redis cluster
â”‚   â”œâ”€â”€ s3.tf                       # S3 buckets
â”‚   â”œâ”€â”€ glue.tf                     # Glue catalog
â”‚   â”œâ”€â”€ dynamodb.tf                 # DynamoDB tables
â”‚   â”œâ”€â”€ lambda.tf                   # Lambda functions
â”‚   â””â”€â”€ outputs.tf                  # Outputs
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.app              # Container aplicaÃ§Ã£o
â”‚   â””â”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o local
â”œâ”€â”€ localstack-init/
â”‚   â””â”€â”€ init.sh                     # Script init LocalStack
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.md             # DocumentaÃ§Ã£o detalhada
â””â”€â”€ README.md                       # Este arquivo
```

## ğŸ”¨ Comandos Ãšteis

```bash
# Terraform
terraform plan -var-file=prod.tfvars
terraform apply -auto-approve
terraform destroy

# AWS CLI
aws emr list-clusters --active
aws emr describe-step --cluster-id <id> --step-id <step-id>
aws s3 sync ./data/ s3://bucket/path/

# Docker
docker-compose up -d
docker-compose logs -f spark-master
docker-compose down -v

# Spark
spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  /app/person_matcher.py
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -am 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

## ğŸ“ Suporte

Para questÃµes e suporte:
- Abra uma issue no GitHub
- Email: suporte@exemplo.com

---

**Desenvolvido com â¤ï¸ usando AWS, Spark, OpenSearch e Terraform**
